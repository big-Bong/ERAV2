{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 6 - Part B\n",
        "\n",
        "#### 1. Less than 20K parameters\n",
        "#### 2. Less than 20 epochs\n",
        "#### 3. At least 99.4% accuracy\n",
        "#### 4. Have used batch normalization and dropout"
      ],
      "metadata": {
        "id": "aUf77khEnxi9"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m2JWFliFfKT"
      },
      "source": [
        "#Import all necessary libraries\n",
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural network architecture\n",
        "\n",
        "\n",
        "\n",
        "1.   1st Convolution layer with 1 input and 16 output channels\n",
        "2.   This is followed by a batch normalization and a max pool layer\n",
        "3. A dropout layer is added after this\n",
        "4. Another block of exact same layers (convolution, batch norm, max pool and dropout). This has 16 channels as input and 32 channels as output\n",
        "5. Third convolution layer with 32 input channels and 32 output channels. This helps in increasing our receptive field while using small number of parameters\n",
        "6. Final convolution layer/output layer, which has 32 inputs and 10 output channels (corresponding to our 10 classes)\n",
        "7. We use a ReLU activation after each of our convolulation layer\n",
        "8. We unroll the final output into a 1X10 output array and apply log_softmax to get out final output\n",
        "\n"
      ],
      "metadata": {
        "id": "0MDQpaf5obIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net,self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 16, 3)\n",
        "    self.norm1 = nn.BatchNorm2d(16)\n",
        "    self.pool1 = nn.MaxPool2d(2, 2)\n",
        "    self.drop1 = nn.Dropout(0.10)\n",
        "    self.conv2 = nn.Conv2d(16, 32, 3)\n",
        "    self.norm2 = nn.BatchNorm2d(32)\n",
        "    self.pool2 = nn.MaxPool2d(2, 2)\n",
        "    self.drop2 = nn.Dropout(0.10)\n",
        "    self.conv3 = nn.Conv2d(32, 32, 3)\n",
        "    self.conv4 = nn.Conv2d(32, 10, 3)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # After 1st conv -> n_in = 28, p = 0, s = 1, k = 3, n_out = 26, j_in = 1, j_out = 1, r_in = 1, r_out = 3\n",
        "    # After 1st Max Pool -> n_in = 26, p = 0, s = 2, k = 2, n_out = 13, j_in = 1, j_out = 2, r_in = 3, r_out = 4\n",
        "    x = self.drop1(self.pool1(self.norm1(F.relu(self.conv1(x)))))\n",
        "    # After 2nd conv -> n_in = 13, p = 0, s = 1, k = 3, n_out = 11, j_in = 2, j_out = 2, r_in = 4, r_out = 8\n",
        "    # After 2nd Max Pool -> n_in = 11, p = 0, s = 2, k = 2, n_out = 5, j_in = 2, j_out = 4, r_in = 8, r_out = 10\n",
        "    x = self.drop2(self.pool2(self.norm2(F.relu(self.conv2(x)))))\n",
        "    # After 3rd conv -> n_in = 5, p = 0, s = 1, k = 3, n_out = 3, j_in = 4, j_out = 4, r_in = 10, r_out = 18\n",
        "    # After 4th conv -> n_in = 13, p = 0, s = 1, k = 3, n_out = 11, j_in = 2, j_out = 2, r_in = 4, r_out = 26\n",
        "    x = F.relu(self.conv4(F.relu(self.conv3(x))))\n",
        "    x = x.view(-1,10)\n",
        "    return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fwwhMKv4a9p9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdydjYTZFyi3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecff6d26-fd43-4c90-f7aa-211f7643a81d"
      },
      "source": [
        "#Creating model summary\n",
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 26, 26]             160\n",
            "       BatchNorm2d-2           [-1, 16, 26, 26]              32\n",
            "         MaxPool2d-3           [-1, 16, 13, 13]               0\n",
            "           Dropout-4           [-1, 16, 13, 13]               0\n",
            "            Conv2d-5           [-1, 32, 11, 11]           4,640\n",
            "       BatchNorm2d-6           [-1, 32, 11, 11]              64\n",
            "         MaxPool2d-7             [-1, 32, 5, 5]               0\n",
            "           Dropout-8             [-1, 32, 5, 5]               0\n",
            "            Conv2d-9             [-1, 32, 3, 3]           9,248\n",
            "           Conv2d-10             [-1, 10, 1, 1]           2,890\n",
            "================================================================\n",
            "Total params: 17,034\n",
            "Trainable params: 17,034\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.28\n",
            "Params size (MB): 0.06\n",
            "Estimated Total Size (MB): 0.35\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Dataloader object for training and testing model"
      ],
      "metadata": {
        "id": "k0XDa4CxsKMC"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqTWLaM5GHgH"
      },
      "source": [
        "torch.manual_seed(1)\n",
        "batch_size = 128\n",
        "\n",
        "kwargs = {'num_workers': 2, 'pin_memory': True} if use_cuda else {}\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.RandomAffine(degrees=20, translate=(0.1,0.1), scale=(0.9, 1.1)),\n",
        "                        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating training and testing methods"
      ],
      "metadata": {
        "id": "Cdg0f5dqsWD8"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fDefDhaFlwH"
      },
      "source": [
        "from tqdm import tqdm\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad() #Preventing gradient accumulation\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target) #Negative log likelihood loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and test the model"
      ],
      "metadata": {
        "id": "jVwL-dxhsl9L"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMWbLWO6FuHb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f37a10b-6cf9-4949-b6bf-36de9b5448a8"
      },
      "source": [
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1, verbose=True)\n",
        "\n",
        "for epoch in range(1, 19):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)\n",
        "    scheduler.step()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adjusting learning rate of group 0 to 1.0000e-02.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.3436274230480194 batch_id=468: 100%|██████████| 469/469 [00:55<00:00,  8.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0529, Accuracy: 9829/10000 (98.29%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.0000e-02.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.14382390677928925 batch_id=468: 100%|██████████| 469/469 [00:54<00:00,  8.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0419, Accuracy: 9873/10000 (98.73%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.0000e-02.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.14485183358192444 batch_id=468: 100%|██████████| 469/469 [00:54<00:00,  8.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0369, Accuracy: 9878/10000 (98.78%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.0000e-02.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.0814553052186966 batch_id=468: 100%|██████████| 469/469 [00:55<00:00,  8.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0331, Accuracy: 9890/10000 (98.90%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.0000e-02.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.08535409718751907 batch_id=468: 100%|██████████| 469/469 [00:55<00:00,  8.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0311, Accuracy: 9894/10000 (98.94%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.0000e-02.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.01914999820291996 batch_id=468: 100%|██████████| 469/469 [00:56<00:00,  8.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0259, Accuracy: 9912/10000 (99.12%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.0000e-02.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.1687787026166916 batch_id=468: 100%|██████████| 469/469 [00:54<00:00,  8.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0270, Accuracy: 9914/10000 (99.14%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.0000e-02.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.1027824878692627 batch_id=468: 100%|██████████| 469/469 [00:53<00:00,  8.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0245, Accuracy: 9922/10000 (99.22%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.0000e-02.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.07965689897537231 batch_id=468: 100%|██████████| 469/469 [00:55<00:00,  8.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0269, Accuracy: 9919/10000 (99.19%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.0000e-02.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.07354914397001266 batch_id=468: 100%|██████████| 469/469 [00:54<00:00,  8.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0233, Accuracy: 9926/10000 (99.26%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.0000e-02.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.0401674248278141 batch_id=468: 100%|██████████| 469/469 [00:55<00:00,  8.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0205, Accuracy: 9934/10000 (99.34%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.0000e-02.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.04188725724816322 batch_id=468: 100%|██████████| 469/469 [00:54<00:00,  8.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0237, Accuracy: 9923/10000 (99.23%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.0000e-02.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.04236917197704315 batch_id=468: 100%|██████████| 469/469 [00:54<00:00,  8.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0228, Accuracy: 9928/10000 (99.28%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.0000e-02.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.07118179649114609 batch_id=468: 100%|██████████| 469/469 [00:55<00:00,  8.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0196, Accuracy: 9938/10000 (99.38%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.0000e-02.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.10333048552274704 batch_id=468: 100%|██████████| 469/469 [00:55<00:00,  8.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0233, Accuracy: 9932/10000 (99.32%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.025090403854846954 batch_id=468: 100%|██████████| 469/469 [00:55<00:00,  8.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0185, Accuracy: 9943/10000 (99.43%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.08566814661026001 batch_id=468: 100%|██████████| 469/469 [00:54<00:00,  8.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0182, Accuracy: 9943/10000 (99.43%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.07856596261262894 batch_id=468: 100%|██████████| 469/469 [00:55<00:00,  8.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0180, Accuracy: 9945/10000 (99.45%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.0000e-03.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So5uk4EkHW6R"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}